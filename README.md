## **DQWB: Dynamic Quantization Weight Boundary Detection Network for Temporal Action Proposal Generation** 
***
Temporal Action Proposal Generation (TAPG) is a critical step of video analysis tasks. To reduce the number of action proposals, recent studies utilize confidence maps generated by quantization weights to refine the proposals. However, these quantization weights are fixed, have a restricted receptive field, and result in the neglect of critical features near action boundaries. In this letter, we propose a Dynamic Quantization Weight Boundary (DQWB) detection network to refine each boundary probabilities. DQWB first predicts boundary sequences, then models the boundary weight quantization as an n-fold Bernoulli distribution, and introduces a dynamic sampling strategy wherein the sampling scope of confidence features is adaptively determined. Finally, confidence maps and quantization feature are used to match the boundary. The extensive experiments on two benchmark datasets of THUMOS14, ActivityNet v1.3 datasets demonstrate the effectiveness of the proposed DQWB compared to state-of-the-art methods. 
***

.<div align=center>![fig1](https://github.com/user-attachments/assets/e9efe847-aec9-46f7-9d23-33139f4ad02a)</div> 
***
.<div align=center>![fig2](https://github.com/user-attachments/assets/2c3738d6-f0dc-478d-b89a-9dd4c0df0e29)</div> 
***
.<div align=center>![tab1](https://github.com/user-attachments/assets/7a4c007f-8545-4e59-8e6e-7cd5f960fefd)</div> 
***
.<div align=center>![tab2](https://github.com/user-attachments/assets/5c4e0025-d502-47f8-b807-c46b675bec60)</div> 
***
.<div align=center>![tab3](https://github.com/user-attachments/assets/d45b33ba-f00b-45ef-b4b1-362483fe7c4a)</div> 
***
.<div align=center>![fig3](https://github.com/user-attachments/assets/b661400e-bea5-43ca-83b5-67e16f448174)</div> 
***
## **Requirements**  
```python
torch
tqdm
pyyaml
pandas
joblib
```  
You can also use this command  
```python
pip install -r requirements.txt
```
***
## **How to use ?**    
Just put these project's items in MCBD and you're ready to go.  

### 1. Download the dataset  
Download the annotations from [here](https://pan.baidu.com/s/1Lo7QwqZm5t_lKeA458GVpQ?pwd=5z75)   
The folder structure should look like
```shell
│
├── anet/
│   ├── data/
│   │   ├── activitynet_annotations
│   │   ├── annotations
│   
├── thumos/
│   ├── data/
│   │   ├── thumos_annotations
│   │   ├── annotations
```
Download the extracted THUMOS14 I3D features from [here](https://pan.baidu.com/s/1Z8SCuOemPDV3peKmA38j4g?pwd=e11W)

Modify the `feature_path` in `thumos/lib/opts.py`  

Download the extracted ActivityNet v1.3 TSP features from [here](https://pan.baidu.com/s/1ka59M1TxEoRnaMcDAB6OMw?pwd=gA16)

Modify the `feat_dir` in `anet/config/config.yaml`  
### 2. Download our training models
***
## **Core File**  
\thumos\lib\model.py  
\anet\lib\model.py  
pointnet_util.py  
train.py  
***
   
## **How to train ?**  
THUMOS14 dataset
```python
cd thumos
sh thomus.sh
```
ActivityNet v1. dataset
```python
cd anet
sh anet.sh
```
***
## **Acknowledgement** 

This implementation is base on [BMN-Boundary-Matching-Network](https://github.com/JJBOY/BMN-Boundary-Matching-Network), [ActionDetection-DBG](https://github.com/Tencent/ActionDetection-DBG), [GTAD](https://github.com/frostinassiky/gtad), and [Multi-Level Content-Aware Boundary Detection-MCBD](https://mic.tongji.edu.cn).
